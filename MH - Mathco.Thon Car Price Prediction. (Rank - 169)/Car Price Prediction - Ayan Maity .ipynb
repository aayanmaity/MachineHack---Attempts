{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MATHCO.THON - CAR PRICE PREDICTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About the Dataset:\n",
    "\n",
    "With the rise in the variety of cars with differentiated capabilities and features such as model, production year, category, brand, fuel type, engine volume, mileage, cylinders, colour, airbags and many more, we are bringing a car price prediction challenge for all. We all aspire to own a car within budget with the best features available. To solve the price problem we have created a dataset of 19237 for the training dataset and 8245 for the test dataset.  \n",
    "                                         - The Math.Co"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading important libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, KFold\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating custom function for RMSLE (Root Mean Squared Log Error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation Metric \n",
    "# Custom fuction for RMSLE\n",
    "def RMSLE(y_true, y_pred):\n",
    "    score = np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Loading train data \n",
    "train_data = pd.read_csv(\"Car Price Prediction/train.csv\")\n",
    "\n",
    "##Loading test data\n",
    "test_data = pd.read_csv(\"Car Price Prediction/test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exploratory Data Analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To speed up the model building process. I am taking advantage of the `Pandas Profiling Library`, which is an open source Python module with which we can quickly do an exploratory data analysis with just few lines of code and generate a detailed report in `html` format. "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from pandas_profiling import ProfileReport\n",
    "Train_Data_EDA = ProfileReport(train_data)\n",
    "Train_Data_EDA.to_file(output_file='Train_EDA.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To view the report please download the report [here](https://drive.google.com/file/d/1u1wZCiFwMTPKu4doIW8oXAoFEObSqf1n/view?usp=sharing)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Dropping duplicated values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dropping duplicated values in train data \n",
    "train_data.drop_duplicates(inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Preprocessing & Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a new feature `Turbo`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['Turbo']=train_data['Engine volume'].replace(['2.0 Turbo', '2.2 Turbo','3.0 Turbo','1.4 Turbo','1.5 Turbo', '1.6 Turbo','2.3 Turbo','2.8 Turbo','1.8 Turbo', '2.4 Turbo', '3.5 Turbo', '3.2 Turbo','1.3 Turbo','2.5 Turbo','1.9 Turbo', '4.4 Turbo', '4.7 Turbo', '0.2 Turbo','4.8 Turbo', '4.6 Turbo','1.2 Turbo','1.7 Turbo', '6.3 Turbo', '2.7 Turbo','2.9 Turbo', '4.0 Turbo','3.6 Turbo','3.7 Turbo','5.5 Turbo','2.1 Turbo','0.7 Turbo', '0.6 Turbo','1.0 Turbo', '4.5 Turbo', '0.8 Turbo', '4.2 Turbo', '5.0 Turbo','5.7 Turbo','0.4 Turbo', '5.4 Turbo', '0.3 Turbo','1.1 Turbo'],'Turbo')\n",
    "train_data['Turbo']=train_data['Turbo'].replace(['3.5','3','1.3','2.5','2','1.8','2.4','4','1.6','3.3','4.7','1.5','4.4','3.6','2.3','2.2','1.4','5.5','3.2','3.8','4.6','1.2','5', '1.7', '2.9', '0.5','1.9','2.7','4.8','5.3','0.4','2.8','1.1','2.1','0.7','5.4','3.7','1','2.6','5.7','3.4','4.3','4.2','5.9','6.8','4.5','0.6','7.3','0.1','6.3','6.4','5.2','5.8','0.8', '6.7', '6.2', '0', '20', '0.3', '0.2','5.6', '6', '3.9', '0.9','3.1'],'Non-Turbo')\n",
    "\n",
    "test_data['Turbo']=test_data['Engine volume'].replace(['2.0 Turbo', '2.2 Turbo','3.0 Turbo','1.4 Turbo','1.5 Turbo', '1.6 Turbo','2.3 Turbo','2.8 Turbo','1.8 Turbo', '2.4 Turbo', '3.5 Turbo', '3.2 Turbo','1.3 Turbo','2.5 Turbo','1.9 Turbo', '4.4 Turbo', '4.7 Turbo', '0.2 Turbo','4.8 Turbo', '4.6 Turbo','1.2 Turbo','1.7 Turbo', '6.3 Turbo', '2.7 Turbo','2.9 Turbo', '4.0 Turbo','3.6 Turbo','3.7 Turbo','5.5 Turbo','2.1 Turbo','0.7 Turbo', '0.6 Turbo','1.0 Turbo', '4.5 Turbo', '0.8 Turbo', '4.2 Turbo', '5.0 Turbo','5.7 Turbo','0.4 Turbo', '5.4 Turbo', '0.3 Turbo','1.1 Turbo','2.6 Turbo','6.0 Turbo'],'Turbo')\n",
    "test_data['Turbo']=test_data['Turbo'].replace(['3.5','3','1.3','2.5','2','1.8','2.4','4','1.6','3.3','4.7','1.5','4.4','3.6','2.3','2.2','1.4','5.5','3.2','3.8','4.6','1.2','5', '1.7', '2.9', '0.5','1.9','2.7','4.8','5.3','0.4','2.8','1.1','2.1','0.7','5.4','3.7','1','2.6','5.7','3.4','4.3','4.2','5.9','6.8','4.5','0.6','7.3','0.1','6.3','6.4','5.2','5.8','0.8', '6.7', '6.2', '0', '20', '0.3', '0.2','5.6', '6', '3.9', '0.9','3.1','6.1','6.6','10.8'],'Non-Turbo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing the string parts associated with the column `Engine volume` and converting the column to appropiate datatype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['Engine volume']=train_data['Engine volume'].str.replace('Turbo','')\n",
    "train_data['Engine volume']=train_data['Engine volume'].astype(float)\n",
    "\n",
    "test_data['Engine volume']=test_data['Engine volume'].str.replace('Turbo','')\n",
    "test_data['Engine volume']=test_data['Engine volume'].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing the string parts associated with the column `Mileage` and converting the column to appropiate datatype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['Mileage']=train_data['Mileage'].str.replace('km',' ')\n",
    "train_data['Mileage']=train_data['Mileage'].astype(int)\n",
    "\n",
    "test_data['Mileage']=test_data['Mileage'].str.replace('km',' ')\n",
    "test_data['Mileage']=test_data['Mileage'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing the discrepancy such as `'-'` in the `Levy` feature and considering them as null values. Imputing the null values with mean method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['Levy']=train_data['Levy'].replace({'-':np.nan})\n",
    "train_data['Levy']=train_data['Levy'].astype(float)\n",
    "train_data['Levy']=train_data['Levy'].fillna(train_data['Levy'].mean())\n",
    "\n",
    "\n",
    "test_data['Levy']=test_data['Levy'].replace({'-':np.nan})\n",
    "test_data['Levy']=test_data['Levy'].astype(float)\n",
    "test_data['Levy']=test_data['Levy'].fillna(train_data['Levy'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a new feature `Age`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['Age'] = 2021 - train_data['Prod. year']\n",
    "\n",
    "test_data['Age'] = 2021 - test_data['Prod. year']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing outliers in the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = train_data.Price.quantile(0.25)\n",
    "Q3 = train_data.Price.quantile(0.75)\n",
    "print(Q1,Q3)\n",
    "\n",
    "\n",
    "IQR = Q3 - Q1\n",
    "print(IQR)\n",
    "\n",
    "lower_limit = Q1 - 1.5*IQR\n",
    "upper_limit = Q3 + 1.5*IQR\n",
    "print( lower_limit,upper_limit)\n",
    "\n",
    "\n",
    "train_data = train_data[(train_data.Price < upper_limit) & (train_data.Price > lower_limit)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the target feature. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = train_data['Price']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping few columns which are not required for the model building. Based on EDA and feature importance from the basic model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.drop(['ID','Prod. year','Price','Model','Manufacturer','Cylinders','Doors'],axis = 1)\n",
    "test_data = test_data.drop(['ID','Prod. year','Price','Model','Manufacturer','Cylinders','Doors'],axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label Encoding the categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbl = LabelEncoder()\n",
    "\n",
    "train_data['Category'] = lbl.fit_transform(train_data['Category'])\n",
    "test_data['Category'] = lbl.transform(test_data['Category'])\n",
    "\n",
    "train_data['Leather interior'] = lbl.fit_transform(train_data['Leather interior'])\n",
    "test_data['Leather interior'] = lbl.transform(test_data['Leather interior'])\n",
    "\n",
    "train_data['Fuel type'] = lbl.fit_transform(train_data['Fuel type'])\n",
    "test_data['Fuel type'] = lbl.transform(test_data['Fuel type'])\n",
    "\n",
    "train_data['Gear box type'] = lbl.fit_transform(train_data['Gear box type'])\n",
    "test_data['Gear box type'] = lbl.transform(test_data['Gear box type'])\n",
    "\n",
    "train_data['Drive wheels'] = lbl.fit_transform(train_data['Drive wheels'])\n",
    "test_data['Drive wheels'] = lbl.transform(test_data['Drive wheels'])\n",
    "\n",
    "train_data['Wheel'] = lbl.fit_transform(train_data['Wheel'])\n",
    "test_data['Wheel'] = lbl.transform(test_data['Wheel'])\n",
    "\n",
    "train_data['Color'] = lbl.fit_transform(train_data['Color'])\n",
    "test_data['Color'] = lbl.transform(test_data['Color'])\n",
    "\n",
    "train_data['Turbo'] = lbl.fit_transform(train_data['Turbo'])\n",
    "test_data['Turbo'] = lbl.transform(test_data['Turbo'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separating numerical columns and categorical columns and creating a separate list for them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = ['Age','Levy','Engine volume','Mileage']\n",
    "cat_cols = [ 'Category','Leather interior', 'Fuel type', 'Gear box type', 'Drive wheels',\n",
    "       'Wheel','Airbags','Turbo','Color']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convering the categorical features into `category` datatype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cat_converter(df):\n",
    "    for i in df[cat_cols]:         \n",
    "            df[i] = df[i].astype('category')\n",
    "            \n",
    "cat_converter(train_data)\n",
    "\n",
    "cat_converter(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardizing numerical features with `Robust Scaler`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit on training data column\n",
    "scale = RobustScaler().fit(train_data[num_cols])\n",
    "# transform the training data column\n",
    "train_data[num_cols] = scale.transform(train_data[num_cols])\n",
    "# transform the testing data column\n",
    "test_data[num_cols] = scale.transform(test_data[num_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dummyfying the categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.get_dummies(train_data, columns = cat_cols)\n",
    "test_data = pd.get_dummies(test_data, columns = cat_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating `train set` and `validation set` for model building and checking model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_data,target, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB_model = XGBRegressor(max_depth = 15,learning_rate=0.1,n_estimators=1000)\n",
    "XGB_model.fit(X_train, y_train)\n",
    "\n",
    "XGB_Model_Y_train_pred = abs(XGB_model.predict(X_train))\n",
    "XGB_Model_Y_test_pred = abs(XGB_model.predict(X_test))\n",
    "\n",
    "Train_score_RF= RMSLE(y_train,XGB_Model_Y_train_pred)\n",
    "Test_score_RF = RMSLE(y_test,XGB_Model_Y_test_pred)\n",
    "\n",
    "print(Train_score_RF)\n",
    "print(Test_score_RF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Search with KFold CV on XGBoost Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gkf = KFold(n_splits=10, shuffle=True, random_state=42).split(X=X_train, y=y_train)\n",
    "\n",
    "param_grid = {\"learning_rate\"    : [0.10, 0.15] ,\n",
    "              \"max_depth\"        : [10,15],\n",
    "              \"n_estimators\"     : [500,1000,2000]}\n",
    "\n",
    "xgb_estimator = XGBRegressor()\n",
    "\n",
    "gsearch = GridSearchCV(estimator=xgb_estimator, param_grid=param_grid, cv=gkf,verbose =0,n_jobs=-1)\n",
    "XGB_model = gsearch.fit(X_train, y_train)\n",
    "\n",
    "XGB_Model_Y_train_pred = abs(XGB_model.predict(X_train))\n",
    "XGB_Model_Y_test_pred = abs(XGB_model.predict(X_test))\n",
    "\n",
    "Train_score_XG= RMSLE(y_train,XGB_Model_Y_train_pred)\n",
    "Test_score_XG = RMSLE(y_test,XGB_Model_Y_test_pred)\n",
    "\n",
    "print(Train_score_XG)\n",
    "print(Test_score_XG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LightGBM Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LGB_model = LGBMRegressor(boosting_type= 'dart', \n",
    "                          num_leaves = 62, \n",
    "                          objective = 'regression_l1', # l2,mape\n",
    "                          max_depth = 10,\n",
    "                          learning_rate = 0.1, # 0.1,0.05,0.001\n",
    "                          metric = 'l1') # l2,mape)\n",
    "\n",
    "\n",
    "LGB_model.fit(X_train, y_train,eval_set = (X_test,y_test),early_stopping_rounds = 50,verbose = 0)\n",
    "\n",
    "LGB_Model_Y_train_pred = abs(LGB_model.predict(X_train))\n",
    "LGB_Model_Y_test_pred = abs(LGB_model.predict(X_test))\n",
    "\n",
    "Train_score_LGB= RMSLE(y_train,LGB_Model_Y_train_pred)\n",
    "Test_score_LGB = RMSLE(y_test,LGB_Model_Y_test_pred)\n",
    "\n",
    "print(Train_score_LGB)\n",
    "print(Test_score_LGB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Search with KFold CV on LightGBM Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gkf = KFold(n_splits=10, shuffle=True, random_state=42).split(X=X_train, y=y_train)\n",
    "\n",
    "param_grid = {\n",
    "    'num_leaves': [31, 62, 127],\n",
    "    'reg_alpha': [0.1, 0.5],\n",
    "    'max_depth': [4,5,6,7,8,10],\n",
    "    'min_data_in_leaf': [30, 50, 100, 300],\n",
    "    'learning_rate': [0.1,0.01,0.001]\n",
    "    }\n",
    "\n",
    "lgb_estimator = LGBMRegressor(boosting_type= 'dart',objective = 'regression_l1')\n",
    "\n",
    "gsearch = GridSearchCV(estimator=lgb_estimator, param_grid=param_grid, cv=gkf,verbose =0,n_jobs=-1)\n",
    "LGB_model = gsearch.fit(X_train, y_train)\n",
    "\n",
    "LGB_Model_Y_train_pred = abs(LGB_model.predict(X_train))\n",
    "LGB_Model_Y_test_pred = abs(LGB_model.predict(X_test))\n",
    "\n",
    "Train_score_LGB= RMSLE(y_train,LGB_Model_Y_train_pred)\n",
    "Test_score_LGB = RMSLE(y_test,LGB_Model_Y_test_pred)\n",
    "\n",
    "print(Train_score_LGB)\n",
    "print(Test_score_LGB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Prediction on test data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Price = abs(XGB_model.predict(test_data))\n",
    "Price = pd.DataFrame(Price,columns = ['Price'])\n",
    "Price.to_csv(\"Model_XGB.csv\",index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
